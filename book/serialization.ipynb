{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Serialization and Preservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://inspirehep.net/record/1698425\"><img src=\"https://raw.githubusercontent.com/matthewfeickert/talk-SciPy-2020/e0c509cd0dfef98f5876071edd4c60aff9199a1b/figures/arXiv_1810-05648_header.png\"></a>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<a href=\"https://twitter.com/lukasheinrich_/status/1052142936803160065\"><img src=\"https://raw.githubusercontent.com/matthewfeickert/talk-SciPy-2020/e0c509cd0dfef98f5876071edd4c60aff9199a1b/figures/pyhf_arXiv.gif\" width=\"300\" height=\"214\" border=\"0\"></a>\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://cds.cern.ch/record/2684863\"><img src=\"https://raw.githubusercontent.com/matthewfeickert/talk-SciPy-2020/e0c509cd0dfef98f5876071edd4c60aff9199a1b/figures/ATLAS_PUB_Note_title.png\"></a>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<a href=\"https://home.cern/news/news/knowledge-sharing/new-open-release-allows-theorists-explore-lhc-data-new-way\"><img src=\"https://raw.githubusercontent.com/matthewfeickert/talk-SciPy-2020/e0c509cd0dfef98f5876071edd4c60aff9199a1b/figures/CERN_news_story.png\" border=\"0\"></a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preserved on HEPData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of PyHEP 2020, ATLAS has published 4 full likelihoods to HEPData\n",
    "\n",
    "<p align=\"center\">\n",
    "<a href=\"https://www.hepdata.net/record/ins1755298?version=2\"><img src=\"https://raw.githubusercontent.com/matthewfeickert/talk-SciPy-2020/e0c509cd0dfef98f5876071edd4c60aff9199a1b/figures/HEPData_likelihoods.png\"></a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "import tarfile\n",
    "import json\n",
    "\n",
    "electroweakino_HEPData_URL = \"https://www.hepdata.net/record/resource/1267798?view=true\"\n",
    "targz_filename = \"1Lbb_workspaces.tar.gz\"\n",
    "response = requests.get(electroweakino_HEPData_URL, stream=True)\n",
    "assert response.status_code == 200\n",
    "with open(targz_filename, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "assert (\n",
    "    hashlib.sha256(open(targz_filename, \"rb\").read()).hexdigest()\n",
    "    == \"64bbbef9f1aaf9e30d75c8975de4789484329b2b825d89331a6f2081661aa728\"\n",
    ")\n",
    "hashlib.sha256(open(targz_filename, \"rb\").read()).hexdigest()\n",
    "# Open as a tarfile\n",
    "tar_archive = tarfile.open(targz_filename, \"r:gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_from_tarfile(tarfile, json_name):\n",
    "    json_file = tarfile.extractfile(tarfile.getmember(json_name)).read().decode(\"utf8\")\n",
    "    return json.loads(json_file)\n",
    "\n",
    "\n",
    "def get_bkg_and_signal(tarfile, directory_name, model_point):\n",
    "    background_only = get_json_from_tarfile(tarfile, directory_name + \"/BkgOnly.json\",)\n",
    "    patchset = pyhf.PatchSet(\n",
    "        get_json_from_tarfile(tarfile, directory_name + \"/patchset.json\")\n",
    "    )\n",
    "    signal_patch = patchset[model_point]\n",
    "    return background_only, signal_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "\n",
    "def calculate_CLs(bkgonly_json, signal_patch_json):\n",
    "    \"\"\"\n",
    "    Calculate the observed CLs and the expected CLs band from a background only\n",
    "    and signal patch.\n",
    "    Args:\n",
    "        bkgonly_json: The JSON for the background only model\n",
    "        signal_patch_json: The JSON Patch for the signal model\n",
    "    Returns:\n",
    "        CLs_obs: The observed CLs value\n",
    "        CLs_exp: List of the expected CLs value band\n",
    "    \"\"\"\n",
    "    workspace = pyhf.workspace.Workspace(bkgonly_json)\n",
    "    model = workspace.model(\n",
    "        measurement_name=None,\n",
    "        patches=[signal_patch_json],\n",
    "        modifier_settings={\n",
    "            \"normsys\": {\"interpcode\": \"code4\"},\n",
    "            \"histosys\": {\"interpcode\": \"code4p\"},\n",
    "        },\n",
    "    )\n",
    "    result = pyhf.infer.hypotest(\n",
    "        1.0, workspace.data(model), model, qtilde=True, return_expected_set=True\n",
    "    )\n",
    "    return result[0].tolist()[0], result[-1].ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneLbb_background, oneLbb_Wh_hbb_750_100_signal_patch = get_bkg_and_signal(\n",
    "    tar_archive, \"1Lbb-likelihoods-hepdata\",(750, 100),  # \"C1N2_Wh_hbb_750_100(750, 100)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs_obs, CLs_exp_band = calculate_CLs(oneLbb_background, oneLbb_Wh_hbb_750_100_signal_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observed: {}, Expected band: {}'.format(CLs_obs, CLs_exp_band))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
